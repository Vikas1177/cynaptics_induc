{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "577891a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T11:06:15.562892Z",
     "iopub.status.busy": "2025-01-16T11:06:15.562611Z",
     "iopub.status.idle": "2025-01-16T11:06:22.643890Z",
     "shell.execute_reply": "2025-01-16T11:06:22.643165Z"
    },
    "papermill": {
     "duration": 7.087772,
     "end_time": "2025-01-16T11:06:22.645418",
     "exception": false,
     "start_time": "2025-01-16T11:06:15.557646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ef71568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T11:06:22.654358Z",
     "iopub.status.busy": "2025-01-16T11:06:22.654056Z",
     "iopub.status.idle": "2025-01-16T11:06:22.658984Z",
     "shell.execute_reply": "2025-01-16T11:06:22.658389Z"
    },
    "papermill": {
     "duration": 0.010682,
     "end_time": "2025-01-16T11:06:22.660276",
     "exception": false,
     "start_time": "2025-01-16T11:06:22.649594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, img_dir):\n",
    "        img_dir = d_path + \"/\" + img_dir + \"/\"\n",
    "        \n",
    "        path_list = os.listdir(img_dir)\n",
    "        abspath = os.path.abspath(img_dir) \n",
    "        \n",
    "        self.img_dir = img_dir\n",
    "        self.img_list = [os.path.join(abspath, path) for path in path_list]\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize([img_size,img_size]),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]), \n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.img_list[idx]\n",
    "        img = Image.open(path).convert('RGB')\n",
    "\n",
    "        img_tensor = self.transform(img)\n",
    "        return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa91ab4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T11:06:22.668250Z",
     "iopub.status.busy": "2025-01-16T11:06:22.668024Z",
     "iopub.status.idle": "2025-01-16T11:06:22.671200Z",
     "shell.execute_reply": "2025-01-16T11:06:22.670573Z"
    },
    "papermill": {
     "duration": 0.008455,
     "end_time": "2025-01-16T11:06:22.672370",
     "exception": false,
     "start_time": "2025-01-16T11:06:22.663915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_path = r\"C:\\Users\\Vikash kumar singh\\Desktop\\dataset\\selfie2anime\"\n",
    "A_dataset = \"trainA\"\n",
    "B_dataset = \"trainB\"\n",
    "img_size = 128\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "939d32ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T11:06:22.680244Z",
     "iopub.status.busy": "2025-01-16T11:06:22.680025Z",
     "iopub.status.idle": "2025-01-16T11:06:22.743948Z",
     "shell.execute_reply": "2025-01-16T11:06:22.743170Z"
    },
    "papermill": {
     "duration": 0.0695,
     "end_time": "2025-01-16T11:06:22.745532",
     "exception": false,
     "start_time": "2025-01-16T11:06:22.676032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_dataset = Dataset(A_dataset)\n",
    "b_dataset = Dataset(B_dataset)\n",
    "\n",
    "data_loader_a = DataLoader(a_dataset, batch_size, shuffle=True)\n",
    "data_loader_b = DataLoader(b_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e6c43a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T11:06:22.753698Z",
     "iopub.status.busy": "2025-01-16T11:06:22.753469Z",
     "iopub.status.idle": "2025-01-16T11:06:22.759247Z",
     "shell.execute_reply": "2025-01-16T11:06:22.758468Z"
    },
    "papermill": {
     "duration": 0.011264,
     "end_time": "2025-01-16T11:06:22.760494",
     "exception": false,
     "start_time": "2025-01-16T11:06:22.749230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,conv_dim=32):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3,conv_dim,kernel_size=4,padding=1,stride=2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(conv_dim, conv_dim*2, 4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(conv_dim*2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(conv_dim*2, conv_dim*4, 4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(conv_dim*4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(conv_dim*4, conv_dim*8, 4, padding=1),\n",
    "            nn.InstanceNorm2d(conv_dim*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(conv_dim*8, 1, 4, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94996ecc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T11:06:22.768400Z",
     "iopub.status.busy": "2025-01-16T11:06:22.768185Z",
     "iopub.status.idle": "2025-01-16T11:06:22.772413Z",
     "shell.execute_reply": "2025-01-16T11:06:22.771636Z"
    },
    "papermill": {
     "duration": 0.009334,
     "end_time": "2025-01-16T11:06:22.773527",
     "exception": false,
     "start_time": "2025-01-16T11:06:22.764193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_channels, in_channels, 3),\n",
    "            nn.InstanceNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_channels, in_channels, 3),\n",
    "            nn.InstanceNorm2d(in_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76306405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T11:06:22.781171Z",
     "iopub.status.busy": "2025-01-16T11:06:22.780953Z",
     "iopub.status.idle": "2025-01-16T11:06:22.786897Z",
     "shell.execute_reply": "2025-01-16T11:06:22.786262Z"
    },
    "papermill": {
     "duration": 0.010993,
     "end_time": "2025-01-16T11:06:22.788020",
     "exception": false,
     "start_time": "2025-01-16T11:06:22.777027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, conv_dim=64, n_res_block=9):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(3, conv_dim, 7),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(conv_dim, conv_dim*2, 3, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(conv_dim*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(conv_dim*2, conv_dim*4, 3, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(conv_dim*4),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            ResidualBlock(conv_dim*4),\n",
    "            ResidualBlock(conv_dim*4),\n",
    "            ResidualBlock(conv_dim*4),\n",
    "            ResidualBlock(conv_dim*4),\n",
    "            ResidualBlock(conv_dim*4),\n",
    "            ResidualBlock(conv_dim*4),\n",
    "            ResidualBlock(conv_dim*4),\n",
    "            ResidualBlock(conv_dim*4),\n",
    "            ResidualBlock(conv_dim*4),\n",
    "\n",
    "            nn.ConvTranspose2d(conv_dim*4, conv_dim*2, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(conv_dim*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(conv_dim*2, conv_dim, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(conv_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(conv_dim, 3, 7),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22ef2341",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T11:06:22.795693Z",
     "iopub.status.busy": "2025-01-16T11:06:22.795496Z",
     "iopub.status.idle": "2025-01-16T11:06:22.798226Z",
     "shell.execute_reply": "2025-01-16T11:06:22.797640Z"
    },
    "papermill": {
     "duration": 0.007789,
     "end_time": "2025-01-16T11:06:22.799393",
     "exception": false,
     "start_time": "2025-01-16T11:06:22.791604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "g_conv_dim = 64\n",
    "d_conv_dim = 64\n",
    "n_res_block = 6  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c9f7897",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T11:06:22.807122Z",
     "iopub.status.busy": "2025-01-16T11:06:22.806927Z",
     "iopub.status.idle": "2025-01-16T11:06:22.810209Z",
     "shell.execute_reply": "2025-01-16T11:06:22.809604Z"
    },
    "papermill": {
     "duration": 0.008465,
     "end_time": "2025-01-16T11:06:22.811431",
     "exception": false,
     "start_time": "2025-01-16T11:06:22.802966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(model, checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()  \n",
    "    return model\n",
    "\n",
    "G_A2B_path = r'G_AtoB_epoch_20.pth'  \n",
    "G_B2A_path = r'G_BtoA_epoch_20.pth'  \n",
    "D_A_path = r'D_A_epoch_20.pth'     \n",
    "D_B_path = r'D_B_epoch_20.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ab55c5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T11:06:22.819391Z",
     "iopub.status.busy": "2025-01-16T11:06:22.819201Z",
     "iopub.status.idle": "2025-01-16T11:06:25.316535Z",
     "shell.execute_reply": "2025-01-16T11:06:25.315832Z"
    },
    "papermill": {
     "duration": 2.502981,
     "end_time": "2025-01-16T11:06:25.318210",
     "exception": false,
     "start_time": "2025-01-16T11:06:22.815229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "G_AtoB = Generator(conv_dim=g_conv_dim, n_res_block=n_res_block).to(device)\n",
    "G_BtoA = Generator(conv_dim=g_conv_dim, n_res_block=n_res_block).to(device)\n",
    "\n",
    "D_A = Discriminator(conv_dim=d_conv_dim).to(device)\n",
    "D_B = Discriminator(conv_dim=d_conv_dim).to(device)\n",
    "\n",
    "G_AtoB = load_model(G_AtoB, G_A2B_path)\n",
    "G_BtoA = load_model(G_BtoA, G_B2A_path)\n",
    "D_A = load_model(D_A, D_A_path)\n",
    "D_B = load_model(D_B, D_B_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f65650a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T11:06:25.327020Z",
     "iopub.status.busy": "2025-01-16T11:06:25.326712Z",
     "iopub.status.idle": "2025-01-16T11:06:25.330695Z",
     "shell.execute_reply": "2025-01-16T11:06:25.330062Z"
    },
    "papermill": {
     "duration": 0.009703,
     "end_time": "2025-01-16T11:06:25.331901",
     "exception": false,
     "start_time": "2025-01-16T11:06:25.322198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def real_mse_loss(D_out):\n",
    "    return torch.mean((D_out - 1) ** 2)\n",
    "\n",
    "def fake_mse_loss(D_out):\n",
    "    return torch.mean(D_out ** 2)\n",
    "\n",
    "def cycle_consistency_loss(real_img, reconstructed_img, lambda_weight):\n",
    "    reconstr_loss = torch.mean(torch.abs(real_img - reconstructed_img))\n",
    "    return lambda_weight * reconstr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a19e02f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T11:06:25.339826Z",
     "iopub.status.busy": "2025-01-16T11:06:25.339595Z",
     "iopub.status.idle": "2025-01-16T11:06:25.343682Z",
     "shell.execute_reply": "2025-01-16T11:06:25.343099Z"
    },
    "papermill": {
     "duration": 0.009293,
     "end_time": "2025-01-16T11:06:25.344900",
     "exception": false,
     "start_time": "2025-01-16T11:06:25.335607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_generator(images_a,images_b,opt_g):\n",
    "    opt_g.zero_grad()\n",
    "    fake_images_a = G_BtoA(images_b)\n",
    "    d_real_a = D_A(fake_images_a)\n",
    "    g_BtoA_loss = real_mse_loss(d_real_a)\n",
    "\n",
    "    recon_b = G_AtoB(fake_images_a)\n",
    "    recon_b_loss = cycle_consistency_loss(images_b, recon_b, lambda_weight=10)\n",
    "\n",
    "\n",
    "    fake_images_b = G_AtoB(images_a)\n",
    "\n",
    "    d_real_b = D_B(fake_images_b)\n",
    "    g_AtoB_loss = real_mse_loss(d_real_b)\n",
    "\n",
    "    recon_a = G_BtoA(fake_images_b)\n",
    "    recon_a_loss = cycle_consistency_loss(images_a, recon_a, lambda_weight=10)\n",
    "\n",
    "    g_total_loss = g_BtoA_loss + g_AtoB_loss + recon_b_loss + recon_a_loss\n",
    "    g_total_loss.backward()\n",
    "    opt_g.step()\n",
    "\n",
    "    return g_total_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fefff0a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T11:06:25.353230Z",
     "iopub.status.busy": "2025-01-16T11:06:25.353011Z",
     "iopub.status.idle": "2025-01-16T11:06:25.357331Z",
     "shell.execute_reply": "2025-01-16T11:06:25.356838Z"
    },
    "papermill": {
     "duration": 0.009859,
     "end_time": "2025-01-16T11:06:25.358573",
     "exception": false,
     "start_time": "2025-01-16T11:06:25.348714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_discriminator(images_a,images_b,opt_d_a,opt_b):\n",
    "    opt_d_a.zero_grad()\n",
    "\n",
    "    d_real_a = D_A(images_a)\n",
    "    d_real_loss_a = real_mse_loss(d_real_a)\n",
    "    \n",
    "    fake_images_a = G_BtoA(images_b)\n",
    "\n",
    "    d_fake_a = D_A(fake_images_a)\n",
    "    d_fake_loss_a = fake_mse_loss(d_fake_a)\n",
    "    \n",
    "    d_a_loss = d_real_loss_a + d_fake_loss_a\n",
    "    d_a_loss.backward()\n",
    "    opt_d_a.step()\n",
    "\n",
    "    opt_d_b.zero_grad()\n",
    "        \n",
    "    d_real_b = D_B(images_b)\n",
    "    d_real_loss_b = real_mse_loss(d_real_b)\n",
    "\n",
    "    fake_images_b = G_AtoB(images_a)\n",
    "\n",
    "    d_fake_b = D_B(fake_images_b)\n",
    "    d_fake_loss_b = fake_mse_loss(d_fake_b)\n",
    "\n",
    "    d_b_loss = d_real_loss_b + d_fake_loss_b\n",
    "    d_b_loss.backward()\n",
    "    opt_d_b.step()\n",
    "\n",
    "    return d_a_loss.item(), d_b_loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbf2a188",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T11:06:25.366896Z",
     "iopub.status.busy": "2025-01-16T11:06:25.366663Z",
     "iopub.status.idle": "2025-01-16T11:06:25.374653Z",
     "shell.execute_reply": "2025-01-16T11:06:25.374032Z"
    },
    "papermill": {
     "duration": 0.013483,
     "end_time": "2025-01-16T11:06:25.375914",
     "exception": false,
     "start_time": "2025-01-16T11:06:25.362431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def denorm(tensor):\n",
    "    return (tensor + 1) / 2  \n",
    "\n",
    "def save_samples_cyclegan(index, real_A, real_B, fake_A, fake_B, show=True,sample_dir = r\"C:\\Users\\Vikash kumar singh\\Desktop\\New folder\\cynaptics_induc\\induction-task\\selfie2anime_output\"):\n",
    "    os.makedirs(sample_dir, exist_ok=True)\n",
    "\n",
    "    fake_A_fname = 'fake_A-{0:0=4d}.png'.format(index)\n",
    "    fake_B_fname = 'fake_B-{0:0=4d}.png'.format(index)\n",
    "    save_image(denorm(fake_A), os.path.join(sample_dir, fake_A_fname), nrow=8)\n",
    "    save_image(denorm(fake_B), os.path.join(sample_dir, fake_B_fname), nrow=8)\n",
    "\n",
    "    real_A_fname = 'real_A-{0:0=4d}.png'.format(index)\n",
    "    real_B_fname = 'real_B-{0:0=4d}.png'.format(index)\n",
    "    save_image(denorm(real_A), os.path.join(sample_dir, real_A_fname), nrow=8)\n",
    "    save_image(denorm(real_B), os.path.join(sample_dir, real_B_fname), nrow=8)\n",
    "\n",
    "    print('Saving', fake_A_fname, fake_B_fname, real_A_fname, real_B_fname)\n",
    "\n",
    "    if show:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        axes = axes.ravel()\n",
    "\n",
    "        axes[0].set_title(\"Real A\")\n",
    "        axes[0].imshow(make_grid(denorm(real_A).cpu(), nrow=8).permute(1, 2, 0))\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        axes[1].set_title(\"Fake B\")\n",
    "        axes[1].imshow(make_grid(denorm(fake_B).cpu(), nrow=8).permute(1, 2, 0))\n",
    "        axes[1].axis('off')\n",
    "\n",
    "        axes[2].set_title(\"Real B\")\n",
    "        axes[2].imshow(make_grid(denorm(real_B).cpu(), nrow=8).permute(1, 2, 0))\n",
    "        axes[2].axis('off')\n",
    "\n",
    "        axes[3].set_title(\"Fake A\")\n",
    "        axes[3].imshow(make_grid(denorm(fake_A).cpu(), nrow=8).permute(1, 2, 0))\n",
    "        axes[3].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9177a36a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T11:06:25.383722Z",
     "iopub.status.busy": "2025-01-16T11:06:25.383512Z",
     "iopub.status.idle": "2025-01-16T11:06:25.390330Z",
     "shell.execute_reply": "2025-01-16T11:06:25.389737Z"
    },
    "papermill": {
     "duration": 0.011993,
     "end_time": "2025-01-16T11:06:25.391411",
     "exception": false,
     "start_time": "2025-01-16T11:06:25.379418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(epochs,dataloader_a,dataloader_b,opt_g,opt_d_a,opt_d_b):\n",
    "    losses = []\n",
    "    loss_g_min = np.Inf\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for(images_a,images_b) in zip(dataloader_a,dataloader_b):\n",
    "            images_a,images_b = images_a.to(device), images_b.to(device)\n",
    "            loss_g = train_generator(images_a,images_b,opt_g)\n",
    "            loss_d_a,loss_d_b = train_discriminator(images_a,images_b,opt_d_a,opt_d_b)\n",
    "        \n",
    "        losses.append((loss_g,loss_d_a,loss_d_b))\n",
    "        end_time = time.time()\n",
    "        total_duration = end_time - start_time\n",
    "        print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d_a: {:.4f},loss_d_b: {:.4f}, duration: {:.4f}\".format(\n",
    "        epoch+1, epochs, loss_g, loss_d_a, loss_d_b, total_duration))\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            with torch.no_grad():  \n",
    "                fake_B = G_AtoB(images_a)  \n",
    "                fake_A = G_BtoA(images_b)  \n",
    "\n",
    "                save_samples_cyclegan(epoch + 1, images_a, images_b, fake_A, fake_B, show=True)\n",
    "                print(f\"Saved generated images for epoch {epoch + 1}\")\n",
    "            torch.save(G_AtoB.state_dict(), f\"G_AtoB_epoch_{epoch + 1}.pth\")\n",
    "            torch.save(G_BtoA.state_dict(), f\"G_BtoA_epoch_{epoch + 1}.pth\")\n",
    "            torch.save(D_A.state_dict(), f\"D_A_epoch_{epoch + 1}.pth\")\n",
    "            torch.save(D_B.state_dict(), f\"D_B_epoch_{epoch + 1}.pth\")\n",
    "\n",
    "        if loss_g < loss_g_min:\n",
    "            loss_g_min = loss_g\n",
    "            \n",
    "            torch.save(G_AtoB.state_dict(), \"G_AtoB_new\")\n",
    "            torch.save(G_BtoA.state_dict(), \"G_BtoA_new\")\n",
    "            \n",
    "            torch.save(D_A.state_dict(), \"D_A_new\")\n",
    "            torch.save(D_B.state_dict(), \"D_B_new\")\n",
    "            \n",
    "            print(\"Models Saved\")\n",
    "            \n",
    "    torch.save(G_AtoB.state_dict(), \"G_AtoB_new_last\")\n",
    "    torch.save(G_BtoA.state_dict(), \"G_BtoA_new_last\")\n",
    "    \n",
    "    torch.save(D_A.state_dict(), \"D_A_new_last\")\n",
    "    torch.save(D_B.state_dict(), \"D_B_new_last\")\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e25ec6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T11:06:25.399090Z",
     "iopub.status.busy": "2025-01-16T11:06:25.398896Z",
     "iopub.status.idle": "2025-01-16T11:06:25.403280Z",
     "shell.execute_reply": "2025-01-16T11:06:25.402651Z"
    },
    "papermill": {
     "duration": 0.009358,
     "end_time": "2025-01-16T11:06:25.404382",
     "exception": false,
     "start_time": "2025-01-16T11:06:25.395024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 0.00002\n",
    "epochs = 20\n",
    "\n",
    "g_params = list(G_AtoB.parameters()) + list(G_BtoA.parameters())\n",
    "opt_g = optim.Adam(g_params, lr, betas=(0.5, 0.999))\n",
    "opt_d_a = optim.Adam(D_A.parameters(), lr, betas=(0.5, 0.999))\n",
    "opt_d_b =  optim.Adam(D_B.parameters(), lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16afa002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T11:06:25.412226Z",
     "iopub.status.busy": "2025-01-16T11:06:25.412032Z",
     "iopub.status.idle": "2025-01-16T13:06:07.330440Z",
     "shell.execute_reply": "2025-01-16T13:06:07.329670Z"
    },
    "papermill": {
     "duration": 7181.924227,
     "end_time": "2025-01-16T13:06:07.332167",
     "exception": false,
     "start_time": "2025-01-16T11:06:25.407940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = train(epochs,data_loader_a,data_loader_b,opt_g,opt_d_a,opt_d_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aba67842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:06:07.401022Z",
     "iopub.status.busy": "2025-01-16T13:06:07.400670Z",
     "iopub.status.idle": "2025-01-16T13:06:07.645243Z",
     "shell.execute_reply": "2025-01-16T13:06:07.644238Z"
    },
    "papermill": {
     "duration": 0.280846,
     "end_time": "2025-01-16T13:06:07.646939",
     "exception": false,
     "start_time": "2025-01-16T13:06:07.366093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(G_AtoB.state_dict(), \"G_AtoB_new_last\")\n",
    "torch.save(G_BtoA.state_dict(), \"G_BtoA_new_last\")\n",
    "\n",
    "torch.save(D_A.state_dict(), \"D_A_new_last\")\n",
    "torch.save(D_B.state_dict(), \"D_B_new_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01eb9aac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:06:07.715972Z",
     "iopub.status.busy": "2025-01-16T13:06:07.715616Z",
     "iopub.status.idle": "2025-01-16T13:06:07.744900Z",
     "shell.execute_reply": "2025-01-16T13:06:07.744262Z"
    },
    "papermill": {
     "duration": 0.065235,
     "end_time": "2025-01-16T13:06:07.746252",
     "exception": false,
     "start_time": "2025-01-16T13:06:07.681017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_path = r\"C:\\Users\\Vikash kumar singh\\Desktop\\dataset\\selfie2anime\"\n",
    "\n",
    "A_test_dataset = \"testA\"\n",
    "B_test_dataset = \"testB\"\n",
    "\n",
    "img_size = 128\n",
    "batch_size = 4\n",
    "\n",
    "a__test_dataset = Dataset(A_test_dataset)\n",
    "b_test_dataset = Dataset(B_test_dataset)\n",
    "\n",
    "data_loader_test_a = DataLoader(a__test_dataset, batch_size, shuffle=False)\n",
    "data_loader_test_b = DataLoader(b_test_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59de443c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:06:07.815306Z",
     "iopub.status.busy": "2025-01-16T13:06:07.814957Z",
     "iopub.status.idle": "2025-01-16T13:06:15.750147Z",
     "shell.execute_reply": "2025-01-16T13:06:15.749263Z"
    },
    "papermill": {
     "duration": 7.977921,
     "end_time": "2025-01-16T13:06:15.758462",
     "exception": false,
     "start_time": "2025-01-16T13:06:07.780541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, (real_A, real_B) in enumerate(zip(data_loader_test_a, data_loader_test_b)):\n",
    "    real_A = real_A.to(device) \n",
    "    real_B = real_B.to(device) \n",
    "\n",
    "    with torch.no_grad():\n",
    "        fake_B = G_AtoB(real_A)  \n",
    "        fake_A = G_BtoA(real_B)  \n",
    "\n",
    "    save_samples_cyclegan(i, real_A, real_B, fake_A, fake_B, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c523761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  \n",
    "    transforms.ToTensor(),          \n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  \n",
    "])\n",
    "  \n",
    "real_A_image = Image.open(r\"C:\\Users\\Vikash kumar singh\\Pictures\\Screenshots\\Screenshot 2025-01-16 192822.png\").convert(\"RGB\")  \n",
    "real_B_image = Image.open(r\"C:\\Users\\Vikash kumar singh\\Pictures\\4365816.jpg\").convert(\"RGB\")\n",
    "\n",
    "real_A = transform(real_A_image).unsqueeze(0).to(device)  \n",
    "real_B = transform(real_B_image).unsqueeze(0).to(device)  \n",
    "\n",
    "with torch.no_grad():\n",
    "    fake_B = G_AtoB(real_A)  \n",
    "    fake_A = G_BtoA(real_B)  \n",
    "\n",
    "save_samples_cyclegan(0, real_A, real_B, fake_A, fake_B, show=True,sample_dir=r\"C:\\Users\\Vikash kumar singh\\Pictures\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3051633,
     "sourceId": 5244594,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6488823,
     "sourceId": 10479303,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 219252,
     "modelInstanceId": 197416,
     "sourceId": 231465,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7204.381107,
   "end_time": "2025-01-16T13:06:17.419646",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-16T11:06:13.038539",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
