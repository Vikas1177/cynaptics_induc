{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install unsloth\n!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-08T18:46:39.859157Z","iopub.execute_input":"2025-01-08T18:46:39.859390Z","iopub.status.idle":"2025-01-08T18:46:53.476838Z","shell.execute_reply.started":"2025-01-08T18:46:39.859367Z","shell.execute_reply":"2025-01-08T18:46:53.475597Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nmax_seq_length = 2048 \ndtype = None \nload_in_4bit = True \n\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/Llama-3.2-1B\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T18:46:53.478157Z","iopub.execute_input":"2025-01-08T18:46:53.478391Z","iopub.status.idle":"2025-01-08T18:47:02.084639Z","shell.execute_reply.started":"2025-01-08T18:46:53.478371Z","shell.execute_reply":"2025-01-08T18:47:02.083705Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 16,\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, \n    bias = \"none\",    \n    use_gradient_checkpointing = \"unsloth\", \n    random_state = 3407,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T18:47:02.085630Z","iopub.execute_input":"2025-01-08T18:47:02.085985Z","iopub.status.idle":"2025-01-08T18:47:07.883403Z","shell.execute_reply.started":"2025-01-08T18:47:02.085925Z","shell.execute_reply":"2025-01-08T18:47:07.882451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_conversation_prompt(persona, conversation, reference):\n    \n    persona_str = \" \".join(persona) if isinstance(persona, list) else persona\n    \n    conversation_str = \"\\n\".join(conversation) if isinstance(conversation, list) else conversation\n\n    template = \"\"\"Below is a persona information of a Person B, followed by a conversation between two individuals, Person A and Person B. Finally, there is a reference to Person B's response in the conversation.\nPlease carefully consider the flow and context of the conversation below, and use the Person B's Persona information appropriately to generate a response that you think are \nthe most appropriate replying for Person B with the help of reference.\n\nPersona: {persona}\nConversation: {conversation}\nReference: {reference}\"\"\"\n    \n    return template.format(\n        persona=persona_str.strip(),\n        conversation=conversation_str.strip(),\n        reference=reference.strip()\n    )\n\ndef formatting_persona_prompts_func(examples):\n    persona_b = examples.get(\"persona_b\", [])\n    dialogue = examples.get(\"dialogue\", [])\n    reference = examples.get(\"reference\", [])\n    \n    texts = []\n    \n    for p, d, r in zip(persona_b, dialogue, reference):\n        if p and d and r:\n            text = generate_conversation_prompt(p, d, r) + EOS_TOKEN  \n            texts.append(text)\n        else:\n            texts.append(\"\")\n\n    return {\"text\": texts}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:01:55.568587Z","iopub.execute_input":"2025-01-08T19:01:55.568887Z","iopub.status.idle":"2025-01-08T19:01:55.575569Z","shell.execute_reply.started":"2025-01-08T19:01:55.568863Z","shell.execute_reply":"2025-01-08T19:01:55.574464Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"examples = {\n    \"persona_b\": [\n        [\"I am most proud of my ability to connect with nature and animals.\", \"I have never been arrested, but my stories might make you think otherwise.\", \"I love family time.\", \"My parents are both school teachers.\", \"I'm afraid of being in a situation where I can't communicate with my wife.\"]\n    ],\n    \"dialogue\": [\n        [\n            \"Persona A: I run every morning before work, it helps me to relieve stress.\",\n            \"Persona B: I can see how that would help; I do much hiking and camping; it helps me to clear my head and connect with nature.\",\n            \"Persona A: That sounds like a lot of fun, and I've always wanted to go camping!\",\n            \"Persona B: It is really great, and you should definitely try it sometime.\",\n            \"Persona A: I will, as for my dogs - it would be lovely.\",\n            \"Persona B: I bet they would. Also, we have dogs, and my dog loves going camping with me.\",\n            \"Persona A: What kind of dog do you have?\"\n        ]\n    ],\n    \"reference\": [\n        \"I have a Golden Retriever named Buddy.\"\n    ]\n}\nformatted_data = formatting_persona_prompts_func(examples)\n\nfor text in formatted_data[\"text\"]:\n    print(text)\n    print(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T18:56:19.084039Z","iopub.execute_input":"2025-01-08T18:56:19.084332Z","iopub.status.idle":"2025-01-08T18:56:19.089794Z","shell.execute_reply.started":"2025-01-08T18:56:19.084306Z","shell.execute_reply":"2025-01-08T18:56:19.088888Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\ndataset_name = \"Cynaptics/persona-chat\"\ndataset = load_dataset(dataset_name, split=\"all\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:02:00.708441Z","iopub.execute_input":"2025-01-08T19:02:00.708734Z","iopub.status.idle":"2025-01-08T19:02:01.753407Z","shell.execute_reply.started":"2025-01-08T19:02:00.708710Z","shell.execute_reply":"2025-01-08T19:02:01.752745Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = dataset.map(formatting_persona_prompts_func, batched = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:02:02.933900Z","iopub.execute_input":"2025-01-08T19:02:02.934276Z","iopub.status.idle":"2025-01-08T19:02:03.629828Z","shell.execute_reply.started":"2025-01-08T19:02:02.934251Z","shell.execute_reply":"2025-01-08T19:02:03.628947Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:02:20.380221Z","iopub.execute_input":"2025-01-08T19:02:20.380533Z","iopub.status.idle":"2025-01-08T19:02:20.386288Z","shell.execute_reply.started":"2025-01-08T19:02:20.380506Z","shell.execute_reply":"2025-01-08T19:02:20.385607Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install huggingface_hub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:28.645138Z","iopub.execute_input":"2025-01-08T19:05:28.645459Z","iopub.status.idle":"2025-01-08T19:05:36.442213Z","shell.execute_reply.started":"2025-01-08T19:05:28.645434Z","shell.execute_reply":"2025-01-08T19:05:36.441160Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:46.586281Z","iopub.execute_input":"2025-01-08T19:05:46.586627Z","iopub.status.idle":"2025-01-08T19:05:46.607369Z","shell.execute_reply.started":"2025-01-08T19:05:46.586604Z","shell.execute_reply":"2025-01-08T19:05:46.606360Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = dataset,\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    dataset_num_proc = 2,\n    packing = False, \n    args = TrainingArguments(\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 4,\n        warmup_steps = 5,\n        num_train_epochs = 1, \n        max_steps = 2000,\n        learning_rate = 2e-4,\n        fp16 = not is_bfloat16_supported(),\n        bf16 = is_bfloat16_supported(),\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs\",\n        report_to = \"none\", \n    ),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:15:10.786285Z","iopub.execute_input":"2025-01-08T19:15:10.786579Z","iopub.status.idle":"2025-01-08T19:15:11.029144Z","shell.execute_reply.started":"2025-01-08T19:15:10.786556Z","shell.execute_reply":"2025-01-08T19:15:11.028510Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:15:13.167725Z","iopub.execute_input":"2025-01-08T19:15:13.168071Z","iopub.status.idle":"2025-01-08T21:37:13.771685Z","shell.execute_reply.started":"2025-01-08T19:15:13.168040Z","shell.execute_reply":"2025-01-08T21:37:13.770823Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nlogs = trainer.state.log_history\ntrain_losses = [log[\"loss\"] for log in logs if \"loss\" in log]\n\n\nplt.plot(train_losses, label=\"Training Loss\")\nplt.xlabel(\"Steps\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training Loss Over Time\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T22:08:34.410475Z","iopub.execute_input":"2025-01-08T22:08:34.410762Z","iopub.status.idle":"2025-01-08T22:08:34.712126Z","shell.execute_reply.started":"2025-01-08T22:08:34.410739Z","shell.execute_reply":"2025-01-08T22:08:34.711310Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.push_to_hub(\"Llama-3.2-1B-persona-chat\") \ntokenizer.push_to_hub(\"Llama-3.2-1B-persona-chat\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T21:39:59.303390Z","iopub.execute_input":"2025-01-08T21:39:59.303677Z","iopub.status.idle":"2025-01-08T21:40:06.939173Z","shell.execute_reply.started":"2025-01-08T21:39:59.303654Z","shell.execute_reply":"2025-01-08T21:40:06.938487Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"max_seq_length = 2048 \ndtype = None \nload_in_4bit = True ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T22:03:06.147417Z","iopub.execute_input":"2025-01-08T22:03:06.147732Z","iopub.status.idle":"2025-01-08T22:03:06.151588Z","shell.execute_reply.started":"2025-01-08T22:03:06.147708Z","shell.execute_reply":"2025-01-08T22:03:06.150689Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"vikas117/Llama-3.2-1B-persona-chat\", \n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n)\nFastLanguageModel.for_inference(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T22:03:07.995566Z","iopub.execute_input":"2025-01-08T22:03:07.995876Z","iopub.status.idle":"2025-01-08T22:03:18.133588Z","shell.execute_reply.started":"2025-01-08T22:03:07.995848Z","shell.execute_reply":"2025-01-08T22:03:18.132789Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_text = \"\"\"Below is a persona information of a Person B, followed by a conversation between two individuals, Person A and Person B. \nPlease carefully consider the flow and context of the conversation below, and use the Person B's Persona information appropriately to generate a response that you think are \nthe most appropriate replying for Person B.\n\n\"Persona\": { My name is David and I'm a 35 year old math teacher.\n I like to hike and spend time in the nature.\n I'm married with two kids\n}\n\"Conversation\": {Persona A: Morning! I think I saw you at the parent meeting, what's your name?\n}\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T22:12:17.394630Z","iopub.execute_input":"2025-01-08T22:12:17.394960Z","iopub.status.idle":"2025-01-08T22:12:17.398517Z","shell.execute_reply.started":"2025-01-08T22:12:17.394914Z","shell.execute_reply":"2025-01-08T22:12:17.397754Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True).to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T22:12:19.767336Z","iopub.execute_input":"2025-01-08T22:12:19.767617Z","iopub.status.idle":"2025-01-08T22:12:19.772869Z","shell.execute_reply.started":"2025-01-08T22:12:19.767595Z","shell.execute_reply":"2025-01-08T22:12:19.772227Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import TextStreamer\ntext_streamer = TextStreamer(tokenizer)\n_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T22:12:22.873014Z","iopub.execute_input":"2025-01-08T22:12:22.873305Z","iopub.status.idle":"2025-01-08T22:12:26.753512Z","shell.execute_reply.started":"2025-01-08T22:12:22.873282Z","shell.execute_reply":"2025-01-08T22:12:26.752835Z"}},"outputs":[],"execution_count":null}]}